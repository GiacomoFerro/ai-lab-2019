{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-LAB SESSION 2: Informed search\n",
    "\n",
    "In the second session we will work on informed search\n",
    "\n",
    "## Maze environments\n",
    "\n",
    "The environments used are again **SmallMaze** (visible in the figure) and its variations\n",
    "![SmallMaze](images/maze.png)\n",
    "The agent starts in cell $(0, 2)$ and has to reach the treasure in $(4, 3)$\n",
    "\n",
    "## Priority Fringe\n",
    "\n",
    "You will need a queue ordered by priority as fringe, or **PriorityFringe**. The difference between the other versions of fringe is that in **PriorityFringe** nodes are removed from the fringe based on the current lowest value. In particular, **FringeNode** has two useful parameters (other than those used in the previous session):\n",
    "* *pathcost* - the path cost from the root node to the current one (defaults to 0)\n",
    "* *value* - value of a node. Used by **PriorityFringe** to order its content (defaults to 0)\n",
    "\n",
    "Here is an example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: 1\n",
      "Added: 2\n",
      "Added: 3\n",
      "Removed: 1\n",
      "Removed: 3\n",
      "Removed: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from utils.fringe import FringeNode, PriorityFringe\n",
    "\n",
    "# Create 3 nodes for state ids 1 2 3\n",
    "node_1 = FringeNode(1) # No parent, pathcost=0, value=0\n",
    "node_2 = FringeNode(2, node_1, node_1.pathcost + 1, 10) # Child of node_1, value=10\n",
    "node_3 = FringeNode(3, node_1, 100, 5)  # Child of node_1, pathcost=100, value=5\n",
    "\n",
    "p_fringe = PriorityFringe()\n",
    "for n in (node_1, node_2, node_3):\n",
    "    p_fringe.add(n)\n",
    "    print(\"Added: {}\".format(n.state))\n",
    "\n",
    "while not p_fringe.is_empty():\n",
    "    print(\"Removed: {}\".format(p_fringe.remove().state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the order in which nodes are removed from the fringe\n",
    "\n",
    "## Uniform-Cost Search (UCS)\n",
    "\n",
    "Before moving to informed search it is useful to see another uninformed search algorithm: the Uniform-Cost Search (UCS). In the following you can see the implementation in *tree search* version. Cost of performing an action is supposd to be 1 (also in the assignements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "Solution: [(0, 1), (1, 1), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import envs\n",
    "from utils.funcs import build_path\n",
    "\n",
    "\n",
    "def ucs(environment):\n",
    "    \"\"\"\n",
    "    Uniform-cost search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        path: solution as a path\n",
    "    \"\"\"\n",
    "    fringe = PriorityFringe()\n",
    "    fringe.add(FringeNode(environment.startstate))\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None\n",
    "        node = fringe.remove()  # Retrieve node from the fringe\n",
    "        if node.state == environment.goalstate:  # Goal state check\n",
    "            return build_path(node)\n",
    "        for action in range(environment.action_space.n):  # Look around\n",
    "            # Child node where value and pathcost are both the pathcost of parent + 1\n",
    "            child = FringeNode(environment.sample(node.state, action), node, node.pathcost + 1, node.pathcost + 1)\n",
    "            fringe.add(child)\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(\"SmallMaze-v0\")\n",
    "env.render()\n",
    "solution = ucs(env)\n",
    "\n",
    "# Print path\n",
    "print(\"\\nSolution: {}\".format([env.state_to_pos(s) for s in solution]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Heuristics\n",
    "\n",
    "Informed search requires a distance heuristic to be used in order to estimate the distance between a state and the goal. You already have at your disposal these functions:\n",
    "* *l1_norm(p1, p2)* - Computes the L1 norm (also known as the manhattan distance) between two points specified as tuples of coordinates\n",
    "* *l2_norm(p1, p2)* - Computes the L2 norm between two points specified as tuples of coordinates\n",
    "* *chebyshev(p1, p2)* - Computes the Chebyshev distance between two points specified as tuples of coordinates. Similar to L1 norm but diagonal moves are also considered\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm heuristic value: 6\n",
      "L2 norm heuristic value: 4.47213595499958\n",
      "Chebyshev heuristic value: 4\n"
     ]
    }
   ],
   "source": [
    "import utils.heuristics as heu\n",
    "\n",
    "p1 = (0, 2)\n",
    "p2 = (4, 0)\n",
    "print(\"L1 norm heuristic value: {}\".format(heu.l1_norm(p1, p2)))\n",
    "print(\"L2 norm heuristic value: {}\".format(heu.l2_norm(p1, p2)))\n",
    "print(\"Chebyshev heuristic value: {}\".format(heu.chebyshev(p1, p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "\n",
    "The first assignment is to implement the Greedy-best-first search algorithm on **SmallMaze**. In particular, you are required to implement both *greedy_tree_search* and *greedy_graph_search* versions that will be called by the generic *greedy*. Use *L1 norm* as heuristic function at first, then try also the others to see the differences.\n",
    "\n",
    "The results returned by *greedy* must be a tuple $(path, stats)$ in the following form:\n",
    "* *path* - tuple of state identifiers forming a path from the start state to the goal state. ``None`` if no solution is found\n",
    "* *stats* - tuple of:\n",
    "     * *time* - time elapsed between the start and the end of the algorithm\n",
    "     * *expc* - number of nodes explored. A node is considered as explored when removed from the fringe and analyzed\n",
    "     * *maxnodes* - maximum number of nodes in memory at the same time (fringe + closed)\n",
    "\n",
    "After the correctness of your implementations have been assessed, you can run the algorithms on other two maze environments: **GrdMaze** and **BlockedMaze**.\n",
    "\n",
    "The next two functions have to be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_tree_search(environment):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Tree search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "        \n",
    "    \"\"\"  \n",
    "    \n",
    "    expc = 0\n",
    "    maxstates = 0\n",
    "\n",
    "    fringe = PriorityFringe();\n",
    "    \n",
    "    pos1=environment.state_to_pos(environment.startstate)\n",
    "    pos2=environment.state_to_pos(environment.goalstate)\n",
    "    \n",
    "    node = FringeNode(environment.startstate, None, 0, heu.l1_norm(pos1,pos2));\n",
    "    fringe.add(node);\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        expc += 1\n",
    "        if fringe.is_empty():\n",
    "            return (None, (expc, maxstates))\n",
    "        node = fringe.remove()\n",
    "        \n",
    "        if node.state == environment.goalstate:\n",
    "            return (build_path(node), (expc, maxstates))\n",
    "        \n",
    "        for action in range(environment.action_space.n):    \n",
    "            \n",
    "            cs = environment.sample(node.state, action)\n",
    "            \n",
    "            posFiglio=environment.state_to_pos(cs)\n",
    "            #posPadre=environment.state_to_pos(node.state)\n",
    "            \n",
    "            child = FringeNode(cs, node, node.pathcost+1, heu.l1_norm(posFiglio,pos2));\n",
    "            \n",
    "            #if child.state not in fringe:\n",
    "            fringe.add(child)\n",
    "            maxstates = max(maxstates, len(fringe))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_graph_search(environment):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Graph search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "        \n",
    "    fringe = PriorityFringe(); \n",
    "    expc = 0\n",
    "    maxstates = 0\n",
    "    \n",
    "    pos1=environment.state_to_pos(environment.startstate)\n",
    "    pos2=environment.state_to_pos(environment.goalstate)\n",
    "    \n",
    "    node = FringeNode(environment.startstate, None, 0, heu.l1_norm(pos1,pos2));\n",
    "    fringe.add(node)\n",
    "    closed = set()\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        if fringe.is_empty():\n",
    "            return (None, (expc, maxstates))\n",
    "        \n",
    "        node = fringe.remove()\n",
    "        expc+=1\n",
    "        \n",
    "        if node.state == environment.goalstate:\n",
    "            return (build_path(node), (expc, maxstates))\n",
    "        \n",
    "        if node.state not in closed:\n",
    "            \n",
    "            \n",
    "            closed.add(node.state)\n",
    "            \n",
    "            for action in range(environment.action_space.n):\n",
    "\n",
    "                cs = environment.sample(node.state, action)\n",
    "\n",
    "                posFiglio=environment.state_to_pos(cs)\n",
    "                #posPadre=environment.state_to_pos(node.state)\n",
    "\n",
    "                child = FringeNode(cs, node, node.pathcost+1, heu.l1_norm(posFiglio,pos2));\n",
    "\n",
    "                #if child.state not in fringe and child.state not in closed:\n",
    "                fringe.add(child)\n",
    "\n",
    "            maxstates = max(maxstates, (len(fringe) + len(closed)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(environment, search_type):\n",
    "    \"\"\"\n",
    "    Greedy-best-first search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        search_type: type of search - greedy_tree_search or greedy_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (time, expc, maxnodes): elapsed time, number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    t = timer()\n",
    "    path, stats = search_type(environment)\n",
    "    return path, (timer() - t, stats[0], stats[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calls your tree search version of Greedy-best-first search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tTREE SEARCH\n",
      "\tEnvironment:  SmallMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-05dd4699e4d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy_tree_search\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Perform Greedy-best-first search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ab136a397456>\u001b[0m in \u001b[0;36mgreedy\u001b[0;34m(environment, search_type)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-86dfb7f7bc0c>\u001b[0m in \u001b[0;36mgreedy_tree_search\u001b[0;34m(environment)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mposFiglio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/ai-lab/envs/obsgrid_env.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mreached\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstaterange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj2sctype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj2sctype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m     \"\"\"\n\u001b[1;32m    689\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtypecode\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mequal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tTREE SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = greedy(env, greedy_tree_search)  # Perform Greedy-best-first search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for Greedy-best-first tree search can be found [here](results/greedy_tree_search_results.txt)\n",
    "\n",
    "The following code calls your graph search version of Greedy-best-first search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tGRAPH SEARCH\n",
      "\tEnvironment:  SmallMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "\n",
      "Execution time: 0.0079s\n",
      "N° of nodes explored: 28\n",
      "Max n° of nodes in memory: 29\n",
      "Solution: [(0, 3), (1, 3), (2, 3), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tGRAPH SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = greedy(env, greedy_graph_search)  # Perform Greedy-best-first search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for Greedy-best-first graph search can be found [here](results/greedy_graph_search_results.txt)\n",
    "\n",
    "## Assignment 2\n",
    "\n",
    "The second assignment is to implement the A* search algorithm on **SmallMaze**. In particular, you are required to implement both *astar_tree_search* and *astar_graph_search* versions that will be called by the generic *astar*. Use *L1 norm* as heuristic function at first, then try also the others to see the differences.\n",
    "\n",
    "The results returned by *astar* must be a tuple $(path, stats)$ in the following form:\n",
    "* *path* - tuple of state identifiers forming a path from the start state to the goal state. ``None`` if no solution is found\n",
    "* *stats* - tuple of:\n",
    "     * *time* - time elapsed between the start and the end of the algorithm\n",
    "     * *expc* - number of nodes explored. A node is considered as explored when removed from the fringe and analyzed\n",
    "     * *maxnodes* - maximum number of nodes in memory at the same time (fringe + closed)\n",
    "\n",
    "After the correctness of your implementations have been assessed, you can run the algorithms on other two maze environments: **GrdMaze** and **BlockedMaze**.\n",
    "\n",
    "The next two functions have to be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_tree_search(environment):\n",
    "    \"\"\"\n",
    "    A* Tree search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    \n",
    "    expc = 0\n",
    "    maxstates = 0\n",
    "\n",
    "    fringe = PriorityFringe();\n",
    "    \n",
    "    pos1=environment.state_to_pos(environment.startstate)\n",
    "    pos2=environment.state_to_pos(environment.goalstate)\n",
    "    \n",
    "    node = FringeNode(environment.startstate, None, 0, 0+heu.l1_norm(pos1,pos2));\n",
    "    fringe.add(node);\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        expc += 1\n",
    "        if fringe.is_empty():\n",
    "            return (None, (expc, maxstates))\n",
    "        node = fringe.remove()\n",
    "        \n",
    "        if node.state == environment.goalstate:\n",
    "            return (build_path(node), (expc, maxstates))\n",
    "        \n",
    "        for action in range(environment.action_space.n):    \n",
    "            \n",
    "            cs = environment.sample(node.state, action)\n",
    "            \n",
    "            posFiglio=environment.state_to_pos(cs)\n",
    "            #posPadre=environment.state_to_pos(node.state)\n",
    "            \n",
    "            child = FringeNode(cs, node, node.pathcost+1, (node.pathcost+1)+heu.l1_norm(posFiglio,pos2));\n",
    "            \n",
    "            #if child.state not in fringe:\n",
    "            fringe.add(child)\n",
    "            maxstates = max(maxstates, len(fringe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_graph_search(environment):\n",
    "    \"\"\"\n",
    "    A* Graph search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    \n",
    "    fringe = PriorityFringe(); \n",
    "    expc = 0\n",
    "    maxstates = 0\n",
    "    \n",
    "    pos1=environment.state_to_pos(environment.startstate)\n",
    "    pos2=environment.state_to_pos(environment.goalstate)\n",
    "    \n",
    "    node = FringeNode(environment.startstate, None, 0, 0+heu.l1_norm(pos1,pos2));\n",
    "    fringe.add(node)\n",
    "    closed = set()\n",
    "\n",
    "    while True:\n",
    "        expc+=1\n",
    "        if fringe.is_empty():\n",
    "            return (None, (expc, maxstates))\n",
    "        \n",
    "        node = fringe.remove()\n",
    "        \n",
    "        \n",
    "        if node.state == environment.goalstate:\n",
    "            return (build_path(node), (expc, maxstates))\n",
    "        \n",
    "        if node.state not in closed:\n",
    "            \n",
    "            closed.add(node.state)\n",
    "            \n",
    "            \n",
    "            for action in range(environment.action_space.n):\n",
    "\n",
    "                cs = environment.sample(node.state, action)\n",
    "\n",
    "                posFiglio=environment.state_to_pos(cs)\n",
    "                #posPadre=environment.state_to_pos(node.state)\n",
    "\n",
    "                child = FringeNode(cs, node, node.pathcost+1, (node.pathcost+1)+heu.l1_norm(posFiglio,pos2));\n",
    "\n",
    "                #if child.state not in fringe and child.state not in closed:\n",
    "                fringe.add(child)\n",
    "\n",
    "            maxstates = max(maxstates, (len(fringe) + len(closed)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(environment, search_type):\n",
    "    \"\"\"\n",
    "    A* search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        search_type: type of search - astar_tree_search or astar_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (time, expc, maxnodes): elapsed time, number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    t = timer()\n",
    "    path, stats = search_type(environment)\n",
    "    return path, (timer() - t, stats[0], stats[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calls your tree search version of A* search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tTREE SEARCH\n",
      "\tEnvironment:  SmallMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "\n",
      "Execution time: 0.8146s\n",
      "N° of nodes explored: 2091\n",
      "Max n° of nodes in memory: 6271\n",
      "Solution: [(0, 1), (1, 1), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tTREE SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = astar(env, astar_tree_search)  # Perform A* search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for A* tree search can be found [here](results/astar_tree_search_results.txt)\n",
    "\n",
    "The following code calls your graph search version of A* search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tGRAPH SEARCH\n",
      "\tEnvironment:  SmallMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "\n",
      "Execution time: 0.0091s\n",
      "N° of nodes explored: 43\n",
      "Max n° of nodes in memory: 34\n",
      "Solution: [(0, 1), (1, 1), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tGRAPH SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = astar(env, astar_graph_search)  # Perform A* search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for A* graph search can be found [here](results/astar_graph_search_results.txt)\n",
    "\n",
    "## Discussion\n",
    "\n",
    "Now that you have correctly implemented both Greedy-best-first and A* what can you say about the solutions they compute? Are there significant differences in the stats? Try to play with other heuristics as well and see if your results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
